{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup development environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role arn: arn:aws:iam::532805286864:role/AdminRole\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri\n",
    "import time\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "print(f\"role arn: {role}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Retrieve the new Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm image uri: 763104351884.dkr.ecr.ap-northeast-2.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi1.3.1-gpu-py310-cu121-ubuntu20.04\n"
     ]
    }
   ],
   "source": [
    "llm_image = get_huggingface_llm_image_uri(\n",
    "  backend=\"huggingface\", # or lmi\n",
    "  region=region\n",
    ")\n",
    "\n",
    "# print ecr image uri\n",
    "print(f\"llm image uri: {llm_image}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# sagemaker config\n",
    "instance_type = \"ml.g5.2xlarge\"\n",
    "number_of_gpu = 1\n",
    "health_check_timeout = 900\n",
    "\n",
    "# Define Model and Endpoint configuration parameter\n",
    "hub = {\n",
    "\t'HF_MODEL_ID':'meta-llama/Llama-2-7b-chat-hf',\n",
    "\t'SM_NUM_GPUS': json.dumps(1),\n",
    "\t'HUGGING_FACE_HUB_TOKEN': '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'\n",
    "}\n",
    "\n",
    "# check if token is set\n",
    "# assert hub['HUGGING_FACE_HUB_TOKEN'] != \"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\", \"You have to provide a token.\"\n",
    "\n",
    "# create HuggingFaceModel with the image uri\n",
    "llm_model = HuggingFaceModel(\n",
    "  role=role,\n",
    "  image_uri=llm_image,\n",
    "  env=hub\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    }
   ],
   "source": [
    "llm = llm_model.deploy(\n",
    "  initial_instance_count=1,\n",
    "  instance_type=instance_type,\n",
    "  container_startup_health_check_timeout=health_check_timeout\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_llama2_prompt(messages):\n",
    "  startPrompt = \"<s>[INST] \"\n",
    "  endPrompt = \" [/INST]\"\n",
    "  conversation = []\n",
    "  for index, message in enumerate(messages):\n",
    "    if message['role'] == \"system\" and index == 0:\n",
    "      conversation.append(f\"<<SYS>>\\n{message['content']}\\n<<</SYS>>\\n\\n\")\n",
    "    elif message['role'] == \"user\":\n",
    "      conversation.append(message['content'].strip())\n",
    "    else:\n",
    "      conversation.append(f\" [/INST] {message['content'].strip()}</s><s>[INST] \")\n",
    "  \n",
    "  return startPrompt + \"\".join(conversation) + endPrompt\n",
    "\n",
    "messages = [\n",
    "  { \"role\": \"system\", \"content\": \"You are a friendly and knowledgeable vacation planning assistant named Clara. Your goal is to have natural conversations with users to help them plan their perfect vacation. \"}\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sagemaker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
